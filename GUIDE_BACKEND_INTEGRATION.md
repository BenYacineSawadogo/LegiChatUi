# üîó Guide d'Int√©gration Backend

Ce guide explique comment utiliser les fichiers de sp√©cification pour cr√©er le backend de Legichat.

## üìÅ Fichiers Disponibles

### 1. `BACKEND_SPECIFICATIONS.md` (Document Principal)
**Fichier de r√©f√©rence complet** contenant :
- ‚úÖ Architecture frontend d√©taill√©e
- ‚úÖ Mod√®les de donn√©es TypeScript
- ‚úÖ Tous les endpoints API avec exemples de requ√™tes/r√©ponses
- ‚úÖ Flux de donn√©es complet
- ‚úÖ Sch√©mas MongoDB recommand√©s
- ‚úÖ Options d'int√©gration IA (OpenAI, Claude, Ollama)
- ‚úÖ Structure de projet backend recommand√©e
- ‚úÖ S√©curit√©, tests, d√©ploiement

**√Ä faire lire en priorit√© √† Claude Code dans votre session backend.**

### 2. `PROMPT_BACKEND.txt` (Prompt Pr√™t √† l'Emploi)
**Prompt concis** √† copier-coller directement dans Claude Code pour d√©marrer la session backend.

Contient :
- Contexte du projet
- T√¢ches principales par ordre de priorit√©
- Contraintes techniques
- Instructions de d√©marrage

### 3. `INTEGRATION_API.md` (Existant)
Guide technique pour connecter le service frontend √† l'API backend.

## üöÄ Comment Utiliser Ces Fichiers

### Option 1 : D√©marrage Rapide (Recommand√©)

1. **Ouvrez une nouvelle session Claude Code** dans votre projet backend

2. **Copiez le contenu de `PROMPT_BACKEND.txt`**

3. **Collez-le dans Claude Code** et ajustez le chemin vers les fichiers :
   ```
   Remplacez :
   /chemin/vers/LegiChatUi/BACKEND_SPECIFICATIONS.md

   Par le chemin r√©el, par exemple :
   /home/user/LegiChatUi/BACKEND_SPECIFICATIONS.md
   ```

4. **Lancez la session** - Claude Code va :
   - Lire automatiquement `BACKEND_SPECIFICATIONS.md`
   - Analyser les mod√®les de donn√©es
   - Proposer une architecture backend
   - Cr√©er les endpoints API n√©cessaires

### Option 2 : D√©marrage Manuel

Si vous pr√©f√©rez guider Claude Code √©tape par √©tape :

1. **Session backend** : "Lis le fichier `/home/user/LegiChatUi/BACKEND_SPECIFICATIONS.md`"

2. Ensuite : "Propose-moi une architecture backend NestJS compatible avec ces sp√©cifications"

3. Puis : "Cr√©e l'endpoint POST /api/chat avec les formats exacts du document"

4. Enfin : "Int√®gre OpenAI GPT-4 pour g√©n√©rer les r√©ponses de l'assistant"

## üìã Checklist d'Impl√©mentation Backend

### Phase 1 : MVP (2-3 heures)
- [ ] Lire `BACKEND_SPECIFICATIONS.md` en entier
- [ ] Cr√©er la structure de projet (NestJS recommand√©)
- [ ] Impl√©menter l'endpoint `POST /api/chat` avec r√©ponses simul√©es
- [ ] Configurer MongoDB (sch√©mas Conversation + Message)
- [ ] Tester avec Postman/curl

### Phase 2 : Int√©gration IA (2-4 heures)
- [ ] Choisir le provider IA (OpenAI GPT-4 / Claude / Ollama)
- [ ] Cr√©er le service IA avec gestion de l'historique
- [ ] Impl√©menter les prompts syst√®me pour Legichat
- [ ] Tester les r√©ponses de l'IA
- [ ] Connecter le frontend au backend r√©el

### Phase 3 : Fonctionnalit√©s Compl√®tes (4-6 heures)
- [ ] Endpoints CRUD pour conversations
- [ ] Endpoint GET /conversations/:id/messages
- [ ] Authentification JWT (optionnel)
- [ ] Validation des entr√©es (Joi/Zod)
- [ ] Gestion des erreurs

### Phase 4 : Production (variables)
- [ ] Rate limiting
- [ ] Caching Redis
- [ ] Logging (Winston/Pino)
- [ ] Tests unitaires et d'int√©gration
- [ ] Documentation Swagger
- [ ] D√©ploiement (Docker, Render, Railway, etc.)

## üîå Connexion Frontend ‚Üî Backend

### 1. Configuration de l'URL API (Frontend)

Dans le frontend Angular, modifiez :

```typescript
// src/app/core/services/chat-api.service.ts

export class ChatApiService implements IChatApi {
  private apiUrl = 'http://localhost:3000/api'; // URL de votre backend

  // OU pour la production :
  // private apiUrl = environment.apiUrl;
}
```

### 2. Configuration CORS (Backend)

Dans votre backend, autorisez le frontend :

```typescript
// NestJS exemple
app.enableCors({
  origin: ['http://localhost:4200', 'https://legichat.com'],
  credentials: true
});

// Express exemple
app.use(cors({
  origin: ['http://localhost:4200', 'https://legichat.com'],
  credentials: true
}));
```

### 3. Test de Connexion

**Backend en local** : `http://localhost:3000`

**Test avec curl** :
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "conversationId": "test-123",
    "message": "Bonjour Legichat"
  }'
```

**R√©ponse attendue** :
```json
{
  "id": "660e8400-e29b-41d4-a716-446655440001",
  "conversationId": "test-123",
  "content": "Bonjour! Comment puis-je vous aider avec des questions juridiques?",
  "role": "assistant",
  "timestamp": "2025-10-21T10:00:00.000Z"
}
```

### 4. D√©marrage des Serveurs

**Terminal 1 - Backend** :
```bash
cd /chemin/vers/backend
npm install
npm run start:dev  # Port 3000
```

**Terminal 2 - Frontend** :
```bash
cd /home/user/LegiChatUi
npm start  # Port 4200
```

Ouvrez http://localhost:4200 et testez le chat !

## ü§ñ Choix du Provider IA

### Option 1 : OpenAI GPT-4 (Recommand√©)
**Avantages** :
- Excellente qualit√© de r√©ponses
- API stable et bien document√©e
- Bonne gestion du contexte fran√ßais/s√©n√©galais

**Co√ªt** : ~$0.03 par 1K tokens (entr√©e) + $0.06 par 1K tokens (sortie)

**Setup** :
```bash
npm install openai
```

### Option 2 : Anthropic Claude
**Avantages** :
- Tr√®s bon en fran√ßais
- Context window de 200K tokens
- Excellent pour les conversations longues

**Co√ªt** : ~$0.015 par 1K tokens (entr√©e) + $0.075 par 1K tokens (sortie)

**Setup** :
```bash
npm install @anthropic-ai/sdk
```

### Option 3 : Ollama (Local, Gratuit)
**Avantages** :
- 100% gratuit
- Pas de limite de requ√™tes
- Donn√©es priv√©es (local)
- Mod√®les : Llama 3.2, Mistral, etc.

**Inconv√©nients** :
- Qualit√© inf√©rieure aux mod√®les commerciaux
- Requiert un GPU puissant pour de bonnes performances

**Setup** :
```bash
# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©charger un mod√®le
ollama pull llama3.2

# Lancer le serveur
ollama serve
```

## üìö Ressources Suppl√©mentaires

### Documentation Frontend
- `README.md` : Documentation g√©n√©rale du frontend
- `INTEGRATION_API.md` : Guide d'int√©gration API
- `RESPONSIVE.md` : D√©tails du design responsive
- `GUIDE_DEMARRAGE.md` : Guide de d√©marrage rapide

### Exemples de Code
- `src/app/core/models/` : Mod√®les de donn√©es TypeScript
- `src/app/core/services/chat-api.service.ts` : Service API frontend
- `src/app/core/interfaces/chat-api.interface.ts` : Interface IChatApi

### Vid√©os/Tutoriels Recommand√©s
- NestJS : https://docs.nestjs.com/
- MongoDB + Mongoose : https://mongoosejs.com/docs/
- OpenAI API : https://platform.openai.com/docs/
- Anthropic Claude : https://docs.anthropic.com/

## üí° Conseils Pratiques

### 1. Commencez Simple
Ne cr√©ez pas toute l'architecture d'un coup. Commencez par :
1. Un simple endpoint POST /api/chat avec r√©ponse fixe "Hello World"
2. Connectez-le au frontend pour v√©rifier que √ßa marche
3. Ajoutez MongoDB
4. Int√©grez l'IA
5. Ajoutez les fonctionnalit√©s avanc√©es

### 2. Testez R√©guli√®rement
Apr√®s chaque √©tape, testez avec :
- Postman pour tester l'API directement
- Le frontend pour tester l'int√©gration compl√®te

### 3. Logs Partout
Ajoutez des logs pour d√©boguer facilement :
```typescript
console.log('[CHAT] Received message:', message);
console.log('[AI] Generating response...');
console.log('[DB] Saving to database...');
```

### 4. Variables d'Environnement
Ne committez JAMAIS vos cl√©s API ! Utilisez `.env` :
```bash
# .env
OPENAI_API_KEY=sk-...
MONGODB_URI=mongodb://localhost:27017/legichat
```

## üêõ R√©solution de Probl√®mes Courants

### Erreur CORS
**Sympt√¥me** : "Access-Control-Allow-Origin" error dans la console frontend

**Solution** :
```typescript
// Backend - Activer CORS
app.enableCors({
  origin: 'http://localhost:4200'
});
```

### Erreur de Format JSON
**Sympt√¥me** : Frontend ne re√ßoit pas les donn√©es correctement

**Solution** : V√©rifiez que les champs correspondent EXACTEMENT √† `BACKEND_SPECIFICATIONS.md` :
- `conversationId` (pas `conversation_id`)
- `role` doit √™tre `"user"` ou `"assistant"` (pas `"bot"`)
- `timestamp` en format ISO 8601

### MongoDB Connection Failed
**Sympt√¥me** : "MongoError: connect ECONNREFUSED"

**Solution** :
```bash
# V√©rifier que MongoDB est lanc√©
sudo systemctl status mongodb

# Ou avec Docker
docker run -d -p 27017:27017 mongo
```

## ‚úÖ Validation Finale

Avant de consid√©rer le backend termin√©, v√©rifiez :

1. **Endpoint POST /api/chat fonctionne** avec le format exact du spec
2. **CORS configur√©** pour le frontend (localhost:4200)
3. **MongoDB connect√©** et sauvegarde les messages
4. **IA g√©n√®re des r√©ponses** pertinentes en fran√ßais
5. **Frontend se connecte** sans erreur
6. **Messages s'affichent** dans les bulles du chat
7. **Conversations persistent** dans la base de donn√©es

## üìû Support

Si vous rencontrez des probl√®mes :

1. **Consultez** `BACKEND_SPECIFICATIONS.md` pour les d√©tails techniques
2. **V√©rifiez** les logs du backend ET du frontend
3. **Testez** l'API avec Postman isol√©ment
4. **Demandez** √† Claude Code de d√©boguer dans votre session backend

---

**Bon d√©veloppement ! üöÄ**

*Cr√©√© le 2025-10-21 pour l'int√©gration backend de Legichat*
